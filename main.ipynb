{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose # = Deconvolution2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# image normalization\n",
    "# find how to use multithreading in jupyter on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showHsv(img):    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 1600, 3)\n",
      "image with its value untouched, but saturation and hue randomized:\n"
     ]
    }
   ],
   "source": [
    "img_in = cv2.imread('pic.jpg')\n",
    "# maybe should switch to LAB colorspace?\n",
    "hsv = cv2.cvtColor(img_in, cv2.COLOR_BGR2HSV)\n",
    "print(hsv.shape)\n",
    "\n",
    "h,s,v = cv2.split(hsv)\n",
    "#print('s',s.shape)\n",
    "s = (np.random.random(s.shape) * 255).astype('uint8')\n",
    "h = (np.random.random(s.shape) * 255).astype('uint8')\n",
    "#s = np.maximum(0, v)\n",
    "#print(s)\n",
    "hsv = cv2.merge([h,s,v])\n",
    "print('image with its value untouched, but saturation and hue randomized:')\n",
    "#showHsv(hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n",
      "(10000,) (10000,)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "X = np.arange(n).reshape(n,1)\n",
    "X = np.hstack((np.ones(n).reshape(n,1), X))\n",
    "print(X.shape)\n",
    "y = np.random.randn(n)*50 + X[:, 1]\n",
    "#y = y.reshape(n,1)\n",
    "print(y.shape, X[:,1].shape)\n",
    "#print(y)\n",
    "#plt.plot(X[:,1], y)\n",
    "yval = y\n",
    "X = np.hstack((X, yval[:,None]))\n",
    "# labels: 1 if above line, 0  below\n",
    "y = y > X[:,1]\n",
    "y = y.reshape(n,1)\n",
    "y = np.hstack((y, ~y )).astype('uint8')\n",
    "print(y.shape)\n",
    "colors = ['red' if i  else 'green' for i in y[:,0]]\n",
    "#plt.scatter(X[:,1], yval, color=colors)\n",
    "#plt.show()\n",
    "#print(y)\n",
    "#print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTestModel(layers):\n",
    "    model = Sequential()\n",
    "    #print(X.shape[1])\n",
    "    model.add(Dense(layers[0], input_dim=X.shape[1], kernel_regularizer=l2(0.001)) ) \n",
    "    model.add(Activation('relu'))\n",
    "    for l in layers[1:]:\n",
    "        model.add(Dense(l, kernel_regularizer=l2(0.001)))\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImgHsv(path):\n",
    "    img_in = cv2.imread(path)\n",
    "    hsv = cv2.cvtColor(img_in, cv2.COLOR_BGR2HSV)\n",
    "    h,s,v = cv2.split(hsv)\n",
    "    X = v\n",
    "    Y = np.dstack((h,s))\n",
    "    #print(\"loadX.shape\", X.shape, 'loadY.shape', Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "# celebA dataset from https://drive.google.com/drive/folders/0B7EVK8r0v71pTUZsaXdaSnZBZzg\n",
    "# 202,599 images of size 178x218\n",
    "\n",
    "# data generator for feeding into memory parts of dataset\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'data generator for feeding into memory parts of dataset'\n",
    "    def __init__(self, list_IDs, batch_size=32, dim=(178,218), in_channels=1,\n",
    "                 out_channels=2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, Y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        # target 2 channels\n",
    "        Y = np.empty((self.batch_size, *self.dim, self.out_channels))\n",
    "        # print(X.shape, Y.shape)\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i], Y[i] = loadImgHsv('data/img_celeba/' + ID)\n",
    "#         print('X[i].shape:',X[0].shape)\n",
    "#         print('X.shape:',X.shape,'Y.shape',Y.shape)\n",
    "        X = np.expand_dims(X, axis=len(X.shape))\n",
    "#         print('X[i].shape:',X[0].shape)\n",
    "#         print('X.shape:',X.shape,'Y.shape',Y.shape)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 202599\n",
      "splitat 2025\n",
      "train len 2025\n",
      "val len 202\n",
      "(32, 218, 178, 2)\n"
     ]
    }
   ],
   "source": [
    "params = {'dim': (218, 178),\n",
    "          'batch_size': 32,\n",
    "          'in_channels': 1,\n",
    "          'out_channels': 2,\n",
    "          'shuffle': True}\n",
    "\n",
    "data_IDs = os.listdir('data/img_celeba/')\n",
    "print('dataset size',len(data_IDs))\n",
    "splitAt = int(len(data_IDs)*0.01)\n",
    "print('splitat', splitAt)\n",
    "train_IDs = data_IDs[:splitAt]\n",
    "print('train len', len(train_IDs))\n",
    "val_IDs = data_IDs[splitAt:int(splitAt + splitAt/10)]\n",
    "print('val len', len(val_IDs))\n",
    "\n",
    "training_generator = DataGenerator(train_IDs, **params)\n",
    "validation_generator = DataGenerator(val_IDs, **params)\n",
    "print(training_generator[0][1].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = []\n",
    "# print(len(training_generator))\n",
    "# for i in range(len(training_generator)):\n",
    "#     tmp.append(training_generator[i])\n",
    "# print(len(tmp))\n",
    "# tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m (None, 6, 5, 32)\n",
      "k (53, 43)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 73, 60, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 36, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 10, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DT (None, 58, 47, 2)         145858    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DT (None, 108, 94, 2)        9794      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DT (None, 161, 141, 2)       10370     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DT (None, 218, 178, 2)       8818      \n",
      "=================================================================\n",
      "Total params: 179,640\n",
      "Trainable params: 179,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(None, 218, 178, 2)\n"
     ]
    }
   ],
   "source": [
    "def createModel(input_shape = (218,178)):\n",
    "    input_shape = input_shape + (1,)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), strides=(3, 3), \n",
    "           activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    print('m',model.output_shape)\n",
    "    kernel_size = np.array(input_shape - np.array(model.output_shape[1:]) + 1)\n",
    "    kernel_size = (kernel_size/4).astype(int)\n",
    "    kernel_size = tuple(kernel_size[:-1])\n",
    "    print('k',kernel_size)\n",
    "    model.add(Conv2DTranspose(filters=2, kernel_size=kernel_size))\n",
    "    kernel_size = (51,48)\n",
    "    model.add(Conv2DTranspose(filters=2, kernel_size=kernel_size))\n",
    "    kernel_size = (54,48)\n",
    "    model.add(Conv2DTranspose(filters=2, kernel_size=kernel_size))\n",
    "    kernel_size = (58,38)\n",
    "    model.add(Conv2DTranspose(filters=2, kernel_size=kernel_size))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['mae','accuracy'])\n",
    "    return model\n",
    "model = createModel()\n",
    "model.summary()\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_8_input:0' shape=(?, 218, 178, 1) dtype=float32>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.layers[0]\n",
    "x.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-tensorboard-17-03-2019-20-02-59-layers-convmax_convmax_4xDeConv\n",
      "m (None, 6, 5, 32)\n",
      "k (53, 43)\n",
      "Epoch 1/3\n",
      "63/63 [==============================] - 28s 450ms/step - loss: 7018.7490 - mean_absolute_error: 57.9654 - acc: 0.6603 - val_loss: 5301.8385 - val_mean_absolute_error: 51.1833 - val_acc: 0.6940\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 22s 350ms/step - loss: 4812.0647 - mean_absolute_error: 49.8008 - acc: 0.6922 - val_loss: 4948.2604 - val_mean_absolute_error: 49.6239 - val_acc: 0.6941\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 22s 347ms/step - loss: 4440.3354 - mean_absolute_error: 48.6524 - acc: 0.6932 - val_loss: 4460.5989 - val_mean_absolute_error: 47.8271 - val_acc: 0.6946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1558068c278>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currTime = time.strftime(\"%d-%m-%Y-%H-%M-%S\", time.localtime())\n",
    "layers = ['convmax_convmax_4xDeConv']\n",
    "NAME = f\"test-tensorboard-{ currTime }-layers-\" + \"_\".join(str(l) for l in layers)\n",
    "print(NAME)\n",
    "\n",
    "model = createModel()\n",
    "tensorboard = TensorBoard(log_dir=f'logs/{NAME}')\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=3,\n",
    "                    use_multiprocessing=False,\n",
    "                    workers=0,\n",
    "                    callbacks=[tensorboard])\n",
    "#mode.fit(X, y, batch_size=32, epochs=10, validation_split=0.2, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImgFromPredict(hs, v):\n",
    "    '''hs- a list containing hue and saturation matrices\n",
    "    v - value matrix.\n",
    "    all three should be uint8\n",
    "    '''\n",
    "    hs, v = hs[0], v[0,...,0]\n",
    "#     print('hs:',hs.shape)\n",
    "    h, s = hs[...,0], hs[...,1]\n",
    "    print('h',h.shape,'s',s.shape,'v',v.shape)\n",
    "    print(h.dtype, s.dtype, v.dtype)\n",
    "    hsv = cv2.merge([h,s,v])\n",
    "    for i in range(3):\n",
    "        pic = hsv[:,:,i]\n",
    "        plt.imshow(pic, cmap='gray')\n",
    "        plt.show()\n",
    "    showHsv(hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 218, 178, 1) (1, 218, 178, 2)\n",
      "float64 1.0 255.0 129.17413153283167\n",
      "-27.0199 115.75167 38.22721\n",
      "0 115 37.89778115658179\n"
     ]
    }
   ],
   "source": [
    "#model.get_config()\n",
    "X, Y = validation_generator[0]\n",
    "X, Y = X[3][None,:], Y[0][None,:]\n",
    "print(X.shape, Y.shape)\n",
    "predY = model.predict(X)\n",
    "\n",
    "print(X.dtype, X.min(), X.max(), X.mean())\n",
    "#predY = int(predY)\n",
    "print(predY.min(), predY.max(), predY.mean() )\n",
    "predY = predY\n",
    "predY = np.maximum(predY, 0)\n",
    "X = X.astype('uint8')\n",
    "predY = predY.astype('uint8')\n",
    "print(predY.min(), predY.max(), predY.mean() )\n",
    "\n",
    "#showImgFromPredict(predY, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected conv2d_transpose_23 to have 4 dimensions, but got array with shape (4, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-b6525d088680>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'loss:{evaluation[0]}\\naccuracy:{evaluation[1]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dzoni\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1435\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1437\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dzoni\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[0;32m    915\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m           exception_prefix='target')\n\u001b[0m\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dzoni\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    180\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected conv2d_transpose_23 to have 4 dimensions, but got array with shape (4, 4)"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(X).reshape((-1,))\n",
    "pred = 1 - pred\n",
    "#print(pred)\n",
    "evaluation = model.evaluate(X, y)\n",
    "print(f'loss:{evaluation[0]}\\naccuracy:{evaluation[1]}')\n",
    "labels = y[:,0]\n",
    "#print(labels.shape, labels)\n",
    "incorrects = np.nonzero(np.not_equal(pred, labels) )\n",
    "print('num incorrect', len(incorrects[0]))\n",
    "#print('incorr:',incorrects)\n",
    "print('\\nwrong pred:', pred[incorrects])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
